{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{"id":"PVbYyQpckbeY"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport copy\nfrom torch.optim import Adam, SGD\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"Mb2ZdMPikdg7","execution":{"iopub.status.busy":"2023-02-12T19:09:43.876838Z","iopub.execute_input":"2023-02-12T19:09:43.877918Z","iopub.status.idle":"2023-02-12T19:09:45.807797Z","shell.execute_reply.started":"2023-02-12T19:09:43.877318Z","shell.execute_reply":"2023-02-12T19:09:45.806779Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"id":"t2LxaRTYmkwz"}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/Input/train.csv')","metadata":{"id":"QPyMQFUVmiwt","execution":{"iopub.status.busy":"2023-02-12T19:09:45.809687Z","iopub.execute_input":"2023-02-12T19:09:45.810525Z","iopub.status.idle":"2023-02-12T19:09:49.065609Z","shell.execute_reply.started":"2023-02-12T19:09:45.810484Z","shell.execute_reply":"2023-02-12T19:09:49.064554Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"id":"YKTzwFMUmxo9","outputId":"44a2df9d-cd92-4912-9a62-2ac1c959347d","execution":{"iopub.status.busy":"2023-02-12T19:09:49.067091Z","iopub.execute_input":"2023-02-12T19:09:49.067463Z","iopub.status.idle":"2023-02-12T19:09:49.119185Z","shell.execute_reply.started":"2023-02-12T19:09:49.067427Z","shell.execute_reply":"2023-02-12T19:09:49.118028Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42000 entries, 0 to 41999\nColumns: 785 entries, label to pixel783\ndtypes: int64(785)\nmemory usage: 251.5 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"data.isnull().values.any()","metadata":{"id":"dMrgYpRqm5P2","outputId":"6665f5c8-c469-443a-af18-b995674660f8","execution":{"iopub.status.busy":"2023-02-12T19:09:49.122320Z","iopub.execute_input":"2023-02-12T19:09:49.122779Z","iopub.status.idle":"2023-02-12T19:09:49.143856Z","shell.execute_reply.started":"2023-02-12T19:09:49.122740Z","shell.execute_reply":"2023-02-12T19:09:49.142990Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"y = data['label']\ndata.drop('label', axis=1, inplace=True)\nX = pd.get_dummies(data, drop_first=True).to_numpy().reshape((-1, 1, 28, 28))","metadata":{"id":"OPXEhmD1nJDw","execution":{"iopub.status.busy":"2023-02-12T19:09:49.145747Z","iopub.execute_input":"2023-02-12T19:09:49.146551Z","iopub.status.idle":"2023-02-12T19:09:49.398927Z","shell.execute_reply.started":"2023-02-12T19:09:49.146503Z","shell.execute_reply":"2023-02-12T19:09:49.397892Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = X, y\nprint(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-12T19:09:49.400567Z","iopub.execute_input":"2023-02-12T19:09:49.400968Z","iopub.status.idle":"2023-02-12T19:09:49.407214Z","shell.execute_reply.started":"2023-02-12T19:09:49.400917Z","shell.execute_reply":"2023-02-12T19:09:49.406062Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(42000, 1, 28, 28)\n(42000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Split data ","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-02-12T19:09:49.408864Z","iopub.execute_input":"2023-02-12T19:09:49.409561Z","iopub.status.idle":"2023-02-12T19:09:49.864557Z","shell.execute_reply.started":"2023-02-12T19:09:49.409525Z","shell.execute_reply":"2023-02-12T19:09:49.863591Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"y_train = y_train.reset_index(drop=True)\ny_val = y_val.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-12T19:09:49.866101Z","iopub.execute_input":"2023-02-12T19:09:49.866477Z","iopub.status.idle":"2023-02-12T19:09:49.872933Z","shell.execute_reply.started":"2023-02-12T19:09:49.866439Z","shell.execute_reply":"2023-02-12T19:09:49.871969Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Creating Dataset & DataLoader","metadata":{"id":"1nOqJf4vnv_K"}},{"cell_type":"code","source":"class MNIST_Set(Dataset):\n    def __init__(self, numpy_data, labels):\n        self.data = numpy_data\n        self.labels = labels\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, index):\n        return torch.from_numpy(self.data[index]).type(torch.FloatTensor), torch.tensor(self.labels[index])","metadata":{"id":"P1t8jtVgnu5n","execution":{"iopub.status.busy":"2023-02-12T19:09:49.874768Z","iopub.execute_input":"2023-02-12T19:09:49.875606Z","iopub.status.idle":"2023-02-12T19:09:49.882769Z","shell.execute_reply.started":"2023-02-12T19:09:49.875569Z","shell.execute_reply":"2023-02-12T19:09:49.881736Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_set = MNIST_Set(X_train, y_train)\nval_set = MNIST_Set(X_val, y_val)\ntest_set = MNIST_Set(X_test, y_test)","metadata":{"id":"2G02PmitqdC5","execution":{"iopub.status.busy":"2023-02-12T19:09:49.886865Z","iopub.execute_input":"2023-02-12T19:09:49.887246Z","iopub.status.idle":"2023-02-12T19:09:49.892549Z","shell.execute_reply.started":"2023-02-12T19:09:49.887219Z","shell.execute_reply":"2023-02-12T19:09:49.891214Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data, label = train_set[1]\nplt.imshow(data[0], cmap='gray')\n\nplt.axis(\"off\")\nplt.show()","metadata":{"id":"HQRzYBVjrD-y","outputId":"a4b467eb-5bd7-48de-9071-f94c58961bbf","execution":{"iopub.status.busy":"2023-02-12T19:09:49.894368Z","iopub.execute_input":"2023-02-12T19:09:49.894714Z","iopub.status.idle":"2023-02-12T19:09:50.009364Z","shell.execute_reply.started":"2023-02-12T19:09:49.894680Z","shell.execute_reply":"2023-02-12T19:09:50.007889Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_set, batch_size=64, shuffle=False, num_workers=0)\ntest_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=0)","metadata":{"id":"Qxh7VRw-rI2L","execution":{"iopub.status.busy":"2023-02-12T19:09:50.011290Z","iopub.execute_input":"2023-02-12T19:09:50.011662Z","iopub.status.idle":"2023-02-12T19:09:50.020116Z","shell.execute_reply.started":"2023-02-12T19:09:50.011626Z","shell.execute_reply":"2023-02-12T19:09:50.018178Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"N8CGeSjzsoUC"}},{"cell_type":"code","source":"class VGG16(nn.Module):\n    def __init__(self, num_classes):\n        super(VGG16, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(), \n            nn.MaxPool2d(kernel_size = 2, stride = 2)\n        )\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2)\n            )\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            )\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(7*7*32, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes))\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        return out","metadata":{"id":"gjTTfZ1Tsrf-","execution":{"iopub.status.busy":"2023-02-12T19:09:50.021786Z","iopub.execute_input":"2023-02-12T19:09:50.022401Z","iopub.status.idle":"2023-02-12T19:09:50.047187Z","shell.execute_reply.started":"2023-02-12T19:09:50.022356Z","shell.execute_reply":"2023-02-12T19:09:50.045300Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"id":"F0fbsCqiDYNw"}},{"cell_type":"code","source":"model = VGG16(10)\nmodel = model.cuda()\nmodel.train()\nepochs = 100\n\noptimizer = Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\nbest_model_wts = copy.deepcopy(model.state_dict())\nbest_acc = 0.0\n\nfor i in range(epochs):\n    loss = 0\n    val_loss = 0\n    correct = 0\n    val_correct = 0\n    \n    for j, batch in enumerate(train_loader):\n        X, labels = batch[0].cuda(), batch[1].cuda()\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(True):\n            y = model(X)\n            loss = criterion(y, labels)\n\n            loss.backward()\n            optimizer.step()\n                    \n            loss += loss.item() * X.shape[0]\n            correct += (y.argmax(1) == labels).float().sum()\n    \n    with torch.no_grad():\n        for j, batch in enumerate(val_loader):\n            X, labels = batch[0].cuda(), batch[1].cuda()\n            y = model(X)\n            val_loss = criterion(y, labels)\n            val_loss += val_loss.item() * X.shape[0]\n            val_correct += (y.argmax(1) == labels).float().sum()\n\n    acc = float(correct) / float(len(train_set))\n    loss = float(loss) / float(len(train_set))\n\n    val_acc = float(val_correct) / float(len(val_set))\n    val_loss = float(val_loss) / float(len(val_set))\n    \n    print(\"Epoch {}: loss: {} acc: {} val_loss: {} val_acc: {}\".format(i + 1, loss, acc, val_loss, val_acc))\n\n    if best_acc < acc:\n        best_acc = acc\n        best_model_wts = copy.deepcopy(model.state_dict())\n        print('Model Saved!')\n\nmodel.load_state_dict(best_model_wts)\nprint('Model\\'s Acc: {}'.format(best_acc))","metadata":{"id":"ELviLFAXtQuo","outputId":"df6cb78b-3634-41d5-91f4-11d4d7b584e9","scrolled":true,"execution":{"iopub.status.busy":"2023-02-12T19:09:50.048824Z","iopub.execute_input":"2023-02-12T19:09:50.049620Z","iopub.status.idle":"2023-02-12T19:16:31.392297Z","shell.execute_reply.started":"2023-02-12T19:09:50.049579Z","shell.execute_reply":"2023-02-12T19:16:31.391103Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1: loss: 0.000175479782690305 acc: 0.9318833415719229 val_loss: 0.0008725816350913738 val_acc: 0.9660130718954248\nModel Saved!\nEpoch 2: loss: 0.00012340423871862337 acc: 0.9747899159663865 val_loss: 0.00048049482422159943 val_acc: 0.9714285714285714\nModel Saved!\nEpoch 3: loss: 0.00013802976697845383 acc: 0.9788103476684792 val_loss: 9.575037061333322e-05 val_acc: 0.9772175536881419\nModel Saved!\nEpoch 4: loss: 1.4022407627592843e-06 acc: 0.9823364639973636 val_loss: 5.658336477675914e-06 val_acc: 0.9803921568627451\nModel Saved!\nEpoch 5: loss: 0.0003054627163796355 acc: 0.9855000823858955 val_loss: 6.635718875461154e-05 val_acc: 0.9811391223155929\nModel Saved!\nEpoch 6: loss: 3.3577025417913065e-07 acc: 0.9863898500576701 val_loss: 3.2318603981331506e-05 val_acc: 0.9837535014005602\nModel Saved!\nEpoch 7: loss: 2.0954805500111759e-07 acc: 0.9866534849233811 val_loss: 4.442675816578691e-06 val_acc: 0.984313725490196\nModel Saved!\nEpoch 8: loss: 2.6769735487471067e-05 acc: 0.9885318833415719 val_loss: 3.777881240755681e-05 val_acc: 0.9813258636788048\nModel Saved!\nEpoch 9: loss: 7.505916570945359e-05 acc: 0.9897841489536991 val_loss: 5.63362990719041e-06 val_acc: 0.9869281045751634\nModel Saved!\nEpoch 10: loss: 5.2129352165419536e-05 acc: 0.98902619871478 val_loss: 0.00025469455398431347 val_acc: 0.9835667600373482\nEpoch 11: loss: 1.08415638411982e-08 acc: 0.9905091448344043 val_loss: 6.853016206418989e-06 val_acc: 0.9850606909430439\nModel Saved!\nEpoch 12: loss: 5.019730465536672e-08 acc: 0.9915636842972483 val_loss: 2.273406162092777e-05 val_acc: 0.9878618113912232\nModel Saved!\nEpoch 13: loss: 6.95201165791221e-07 acc: 0.99166254737189 val_loss: 1.0496578296693432e-05 val_acc: 0.988608776844071\nModel Saved!\nEpoch 14: loss: 1.627334600265699e-06 acc: 0.9924864063272367 val_loss: 4.5104381862252145e-06 val_acc: 0.9869281045751634\nModel Saved!\nEpoch 15: loss: 1.0352200555494971e-07 acc: 0.9923216345361674 val_loss: 7.464672698805424e-06 val_acc: 0.9850606909430439\nEpoch 16: loss: 2.5857097478017203e-08 acc: 0.9930466304168726 val_loss: 1.581060855773762e-06 val_acc: 0.9845004668534081\nModel Saved!\nEpoch 17: loss: 2.5772002078611193e-07 acc: 0.9923875432525952 val_loss: 0.00010218177300318727 val_acc: 0.9882352941176471\nEpoch 18: loss: 2.458783915927175e-06 acc: 0.9939363980886472 val_loss: 4.40330008943987e-06 val_acc: 0.98468720821662\nModel Saved!\nEpoch 19: loss: 3.1618724585875863e-06 acc: 0.9947932114022079 val_loss: 3.6704033112325587e-06 val_acc: 0.9871148459383754\nModel Saved!\nEpoch 20: loss: 7.096946872936519e-07 acc: 0.9941670785961444 val_loss: 3.434008076077416e-06 val_acc: 0.9850606909430439\nEpoch 21: loss: 4.062051876389935e-07 acc: 0.9945625308947108 val_loss: 1.9227991525838577e-07 val_acc: 0.9873015873015873\nEpoch 22: loss: 5.295742005428975e-08 acc: 0.994496622178283 val_loss: 2.3407896025841978e-05 val_acc: 0.9871148459383754\nEpoch 23: loss: 1.9755551594891565e-08 acc: 0.9960125226561213 val_loss: 5.298705439385023e-07 val_acc: 0.9859943977591037\nModel Saved!\nEpoch 24: loss: 1.221661504881644e-08 acc: 0.9940352611632889 val_loss: 1.3601053662660743e-05 val_acc: 0.9863678804855276\nEpoch 25: loss: 8.763895046428119e-08 acc: 0.994529576536497 val_loss: 2.956571993109336e-07 val_acc: 0.9869281045751634\nEpoch 26: loss: 2.1270489171920763e-08 acc: 0.9954852529246992 val_loss: 7.95521516871163e-06 val_acc: 0.9897292250233427\nEpoch 27: loss: 1.0969574397626554e-05 acc: 0.9951557093425606 val_loss: 6.552931290019014e-07 val_acc: 0.9878618113912232\nEpoch 28: loss: 1.1971593309794782e-08 acc: 0.9965397923875432 val_loss: 6.876035004742896e-07 val_acc: 0.9873015873015873\nModel Saved!\nEpoch 29: loss: 1.3784283069590797e-07 acc: 0.9958807052232658 val_loss: 2.279105038842122e-07 val_acc: 0.98468720821662\nEpoch 30: loss: 5.099423380694764e-06 acc: 0.995551161641127 val_loss: 5.483999500532889e-07 val_acc: 0.9876750700280112\nEpoch 31: loss: 7.033630748874647e-08 acc: 0.9960125226561213 val_loss: 2.1854784238794828e-07 val_acc: 0.9901027077497666\nEpoch 32: loss: 8.7736675650505e-07 acc: 0.995847750865052 val_loss: 3.6604591383556134e-08 val_acc: 0.9874883286647993\nEpoch 33: loss: 0.00010491632947734758 acc: 0.9971659251936068 val_loss: 0.0003433553444571188 val_acc: 0.9889822595704949\nModel Saved!\nEpoch 34: loss: 9.787449001539163e-06 acc: 0.9954193442082715 val_loss: 4.487674053754904e-05 val_acc: 0.9899159663865547\nEpoch 35: loss: 2.756235732201749e-07 acc: 0.997100016477179 val_loss: 8.896565417838253e-07 val_acc: 0.9880485527544351\nEpoch 36: loss: 1.2098442659354087e-08 acc: 0.9967704728950404 val_loss: 1.1532334393424257e-06 val_acc: 0.9867413632119515\nEpoch 37: loss: 6.695325099807101e-07 acc: 0.9959466139396935 val_loss: 1.74637972164193e-07 val_acc: 0.9863678804855276\nEpoch 38: loss: 1.0999645020022146e-09 acc: 0.9960125226561213 val_loss: 5.6040230668893385e-06 val_acc: 0.988608776844071\nEpoch 39: loss: 7.991716666965032e-09 acc: 0.9972977426264623 val_loss: 3.037657927857394e-07 val_acc: 0.9880485527544351\nModel Saved!\nEpoch 40: loss: 2.618976275115263e-11 acc: 0.9969681990443237 val_loss: 2.1180442780478884e-07 val_acc: 0.988795518207283\nEpoch 41: loss: 8.860817995084449e-10 acc: 0.9969681990443237 val_loss: 6.465432621072543e-07 val_acc: 0.988608776844071\nEpoch 42: loss: 3.0991107641743374e-10 acc: 0.9975613774921733 val_loss: 4.009966739391635e-07 val_acc: 0.9867413632119515\nModel Saved!\nEpoch 74: loss: 6.70760032725621e-08 acc: 0.9985500082385895 val_loss: 2.0501106047770662e-10 val_acc: 0.9878618113912232\nEpoch 75: loss: 8.696811892120464e-08 acc: 0.9980886472235954 val_loss: 2.6832892447292638e-05 val_acc: 0.9908496732026144\nEpoch 76: loss: 9.951977857061236e-10 acc: 0.9981875102982369 val_loss: 1.1594339683008433e-08 val_acc: 0.9891690009337069\nEpoch 77: loss: 5.700426140281745e-09 acc: 0.9975943318503873 val_loss: 2.888718795598277e-06 val_acc: 0.9901027077497666\nEpoch 78: loss: 1.6586817085607448e-10 acc: 0.9982204646564509 val_loss: 1.2938075220207123e-08 val_acc: 0.9865546218487395\nEpoch 79: loss: 0.0 acc: 0.9981875102982369 val_loss: 1.115127563142643e-06 val_acc: 0.9902894491129786\nEpoch 80: loss: 1.111587068020885e-08 acc: 0.998681825671445 val_loss: 0.00024011119518404692 val_acc: 0.9899159663865547\nModel Saved!\nEpoch 81: loss: 1.8483048685792448e-07 acc: 0.9979238754325259 val_loss: 5.359936637732606e-07 val_acc: 0.9869281045751634\nEpoch 82: loss: 0.0 acc: 0.9980886472235954 val_loss: 5.803215747871319e-08 val_acc: 0.9902894491129786\nEpoch 83: loss: 3.6838423964977362e-09 acc: 0.9986159169550173 val_loss: 4.988552453661604e-09 val_acc: 0.9897292250233427\nEpoch 84: loss: 1.3924084846553367e-09 acc: 0.9989784148953699 val_loss: 1.8512934140241893e-05 val_acc: 0.988422035480859\nModel Saved!\nEpoch 85: loss: 0.0 acc: 0.9983852364475202 val_loss: 1.425941493866546e-08 val_acc: 0.9908496732026144\nEpoch 86: loss: 6.773794014028337e-09 acc: 0.9981545559400231 val_loss: 2.252429081987934e-07 val_acc: 0.9880485527544351\nEpoch 87: loss: 0.0 acc: 0.9983522820893063 val_loss: 5.398552325540279e-09 val_acc: 0.988608776844071\nEpoch 88: loss: 1.6712782326591607e-07 acc: 0.9983193277310924 val_loss: 1.441880528633348e-08 val_acc: 0.9897292250233427\nEpoch 89: loss: 8.729923102495663e-12 acc: 0.9983522820893063 val_loss: 7.995295061805502e-09 val_acc: 0.9904761904761905\nEpoch 90: loss: 0.0 acc: 0.9986488713132312 val_loss: 5.147995791497121e-09 val_acc: 0.9901027077497666\nEpoch 91: loss: 0.0 acc: 0.9988136431043005 val_loss: 3.6443593667474004e-08 val_acc: 0.9891690009337069\nEpoch 92: loss: 4.140007366240761e-08 acc: 0.9984840995221618 val_loss: 3.7445988285204834e-08 val_acc: 0.9902894491129786\nEpoch 93: loss: 1.0999540718108744e-09 acc: 0.9983522820893063 val_loss: 8.177575123749402e-09 val_acc: 0.9906629318394025\nEpoch 94: loss: 4.3649615512478315e-12 acc: 0.998714780029659 val_loss: 1.4031369714753356e-08 val_acc: 0.9914098972922503\nEpoch 95: loss: 5.674447066271721e-11 acc: 0.9982204646564509 val_loss: 2.0728810911760755e-09 val_acc: 0.9889822595704949\nEpoch 96: loss: 4.3649615512478315e-12 acc: 0.9985500082385895 val_loss: 4.61245874807336e-08 val_acc: 0.9891690009337069\nEpoch 97: loss: 1.846334487945578e-09 acc: 0.9989125061789421 val_loss: 1.6400840679743614e-09 val_acc: 0.9908496732026144\nEpoch 98: loss: 2.618976275115263e-11 acc: 0.9986488713132312 val_loss: 5.6051183926736384e-08 val_acc: 0.988795518207283\nEpoch 99: loss: 0.0 acc: 0.9982534190146647 val_loss: 0.0009417506270493223 val_acc: 0.9895424836601308\nEpoch 100: loss: 0.0 acc: 0.9982534190146647 val_loss: 0.0002697173732112881 val_acc: 0.988608776844071\nModel's Acc: 0.9989784148953699\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test","metadata":{"id":"zfQ_esitLjKC"}},{"cell_type":"code","source":"model.eval()\ntest_correct = 0\nfor i, batch in enumerate(test_loader):\n    X, labels = batch[0].cuda(), batch[1].cuda()\n    y = model(X)\n    test_correct += (y.argmax(1) == labels).float().sum()\ntest_acc = float(test_correct) / float(len(test_set))\nprint(\"Test Accuracy: {}\".format(test_acc))","metadata":{"id":"5KBhRJW9LlZk","execution":{"iopub.status.busy":"2023-02-12T19:16:31.394046Z","iopub.execute_input":"2023-02-12T19:16:31.394416Z","iopub.status.idle":"2023-02-12T19:16:31.671061Z","shell.execute_reply.started":"2023-02-12T19:16:31.394382Z","shell.execute_reply":"2023-02-12T19:16:31.670015Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9934920634920635\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"code","source":"model = model.cpu()\ntorch.save(model.state_dict(), 'model.pt')","metadata":{"execution":{"iopub.status.busy":"2023-02-12T19:16:31.672770Z","iopub.execute_input":"2023-02-12T19:16:31.673200Z","iopub.status.idle":"2023-02-12T19:16:31.691772Z","shell.execute_reply.started":"2023-02-12T19:16:31.673162Z","shell.execute_reply":"2023-02-12T19:16:31.690928Z"},"trusted":true},"execution_count":16,"outputs":[]}]}